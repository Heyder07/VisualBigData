{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Avanzado\n",
    "\n",
    "## Visualización de grandes bases de datos\n",
    "\n",
    "### Eyder Uriel Kinil Cervera "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Este challenge avanzado permitirá a los estudiantes aplicar PySpark para analizar grandes volúmenes de datos relacionados con un tema cercano a su investigación de tesis, integrando los conocimientos adquiridos en los challenges anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo general\n",
    "\n",
    "Realizar un análisis avanzado utilizando PySpark, relacionando el proyecto con su tema de tesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo especifico\n",
    "\n",
    "Utilizar APIs avanzadas como Spark Streaming o Spark ML para trabajar con una gran base de datos en tiempo real o construir un modelo predictivo complejo. Los estudiantes deberán crear una presentación de su análisis y presentarla al grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ruta del csv\n",
    "file_path = \"../winequality-white.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyspark con regresión logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"WineQualityPredictor\").getOrCreate()\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "data = spark.read.csv(file_path, header=True, inferSchema=True, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fixed acidity: double (nullable = true)\n",
      " |-- volatile acidity: double (nullable = true)\n",
      " |-- citric acid: double (nullable = true)\n",
      " |-- residual sugar: double (nullable = true)\n",
      " |-- chlorides: double (nullable = true)\n",
      " |-- free sulfur dioxide: double (nullable = true)\n",
      " |-- total sulfur dioxide: double (nullable = true)\n",
      " |-- density: double (nullable = true)\n",
      " |-- pH: double (nullable = true)\n",
      " |-- sulphates: double (nullable = true)\n",
      " |-- alcohol: double (nullable = true)\n",
      " |-- quality: integer (nullable = true)\n",
      "\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|fixed acidity|volatile acidity|citric acid|residual sugar|chlorides|free sulfur dioxide|total sulfur dioxide|density|  pH|sulphates|alcohol|quality|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|          7.0|            0.27|       0.36|          20.7|    0.045|               45.0|               170.0|  1.001| 3.0|     0.45|    8.8|      6|\n",
      "|          6.3|             0.3|       0.34|           1.6|    0.049|               14.0|               132.0|  0.994| 3.3|     0.49|    9.5|      6|\n",
      "|          8.1|            0.28|        0.4|           6.9|     0.05|               30.0|                97.0| 0.9951|3.26|     0.44|   10.1|      6|\n",
      "|          7.2|            0.23|       0.32|           8.5|    0.058|               47.0|               186.0| 0.9956|3.19|      0.4|    9.9|      6|\n",
      "|          7.2|            0.23|       0.32|           8.5|    0.058|               47.0|               186.0| 0.9956|3.19|      0.4|    9.9|      6|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar información del dataset\n",
    "data.printSchema()\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas de características (sin la columna de calidad)\n",
    "feature_columns = [col for col in data.columns if col != 'quality']\n",
    "\n",
    "# Usar VectorAssembler para combinar las columnas en un solo vector de características\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "assembled_data = assembler.transform(data)\n",
    "\n",
    "# Crear columna 'label' que será 1 si la calidad es alta (>= 7), 0 si es baja\n",
    "data_with_label = assembled_data.withColumn(\"label\", (col(\"quality\") >= 7).cast(\"double\"))\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
    "train_data, test_data = data_with_label.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Crear el modelo de regresión logística\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones sobre los datos de prueba\n",
    "predictions = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC del modelo: 0.6220870902355491\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo usando la curva ROC\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\")\n",
    "roc = evaluator.evaluate(predictions)\n",
    "print(f\"ROC del modelo: {roc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyspark con support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"SVMExample\").getOrCreate()\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "data = spark.read.csv(file_path, header=True, inferSchema=True, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las columnas de características (sin la columna de calidad)\n",
    "feature_columns = [col for col in data.columns if col != 'quality']\n",
    "\n",
    "# Usar VectorAssembler para combinar las columnas en un solo vector de características\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "assembled_data = assembler.transform(data)\n",
    "\n",
    "# Crear columna 'label' que será 1 si la calidad es alta (>= 7), 0 si es baja\n",
    "data_with_label = assembled_data.withColumn(\"label\", (col(\"quality\") >= 7).cast(\"double\"))\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
    "train_data, test_data = data_with_label.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Crear el modelo de SVM (LinearSVC)\n",
    "svm = LinearSVC(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "svm_model = svm.fit(train_data)\n",
    "\n",
    "# Hacer predicciones sobre los datos de prueba\n",
    "predictions = svm_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC del modelo: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo usando AUC (Área bajo la curva ROC)\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"AUC del modelo: {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones \n",
    "\n",
    "En este ejercicio se emplea la base de datos del vino blanco para probar un modelo ML de regrsión logistica en un entorno se Spark, se observa una presión similar de 0.62 vs 0.62 del modelo Ramdon Forest con la base de datos de vino tinto. \n",
    "\n",
    "Sin embargo al realizar la comparativa del modelo de regresion lineal vs el modelo SVM para la prediccion de la calidad del vino, se observa un desempeño mejor en la regresión logistica de 0.62 vs 0.5.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EYDER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
